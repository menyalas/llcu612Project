{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LLCU612 Final Project (Winter 2019)</h1>\n",
    "<h2>Pandas and Seaborn for Sentiment and Topic Analysis of Twitter Data</h2>\n",
    "<p>By Sunyam Bagga and Alayne Moody</p>\n",
    "<p>April 19, 2019</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Our team is comprised of a computer scientist, Sunyam Bagga, and a digital humanist, Alayne Moody. We have disparate but complementary skills and research interests. Our collaboration developed with ease, beginning with a brief word in class, followed by a Spring Break email exchange about a project idea and the quick recognition that we had enough common ground to form a team. We each came to the table with particular abilities, resources and ideas. In addition to management and writing skills, Alayne provided:<ul> \n",
    "    <li>the dataset (a custom collection of tweets), </li>\n",
    "    <li>a journal article to serve as a starting point (Ozturk & Ayvaz, 2018), and </li>\n",
    "    <li>a workflow and toolkit proposal - weekly meetings, with Asana for communication, Dropbox for data and GitHub for code. </li></ul>\n",
    "With his programming skills and experience working with text-based data projects, Sunyam was well positioned to set our technical skill building objectives, which were to develop our capacities with:<ul>\n",
    "    <li>Pandas for manipulating, processing and analyzing data,</li>\n",
    "    <li>Matplotlib and Seaborn for data visualizations,</li>\n",
    "    <li>VADER for calculating sentiment scores, and</li>\n",
    "    <li>Gensim for modelling topics.</li></ul>\n",
    "As the project developed, our third team member, Stefan, contributed ideas, such as adding an automatic language detector and a second form of sentiment scoring.</p>\n",
    "<p>Our objective was to partially replicate and extend the work of Nazan Ozturk and Serkan Ayvaz in their 2018 <i>Telematics and Informatics</i> paper \"Sentiment analysis on Twitter: A text mining approach to the Syrian refugee crisis.\" Our dataset is an original collection of 123,524 tweets harvested between January 21 and March 4, 2019, through the Twitter Archiving Google Sheet (TAGS), which interfaces with the Twitter Search API. Our research question was: How do the tweets in our collection vary, particularly in terms of time, sentiment, topic and author location.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Starting Point & Digressions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ozturk and Ayvaz (2018) compare sentiment in 2,381,197 English and Turkish language tweets collected via the Twitter Search API between March 29 and April 30, 2017. Search criteria included the keywords \"Syrian,\" \"refugee\" and three corresponding Turkish words. Although Turkey was accepting more Syrian refugees than the United States, the sentiment of Turkish tweets was more positive than the sentiment of U.S. tweets. Most notably, 35% of Turkish tweets carried positive sentiment compared to only 12% for U.S. tweets. We agreed this article could serve as a good starting point for our project because it offered compelling subject matter (migration), methods that were relevant and offered the right balance of challenge and feasibility, and opportunities for improvement, especially in terms of the topic analysis, data visualization and interpretation of results.</p>\n",
    "<p>For our partial replication, we focus on English language tweets for multiple reasons, the most important being the distribution of languages in our dataset. The authors of 106,942 tweets indicated English as their primary language, followed by 4,523 for French, 3,016 for German and 2,488 for Spanish. The representation of other languages declined steeply from there. The United States also heavily dominated the author location variable. With these distributions in mind, we decided to focus on English language tweets and compare sentiment by author location. This approach also addressed a shortcoming we perceived in the original study: the lack of a baseline showing whether English language tweets were generally negative. While our modification would not allow us to address this exact issue, it would shed light on whether English tweets coming from the United States were more negative than English tweets from other parts of the world.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preparation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We used NLTK for text processing and Pandas for data processing and summary statistics. Our original dataset included the following information:<ul> \n",
    "    <li><b>tweet level</b>. ID, time, date, components (e.g., hashtags, user mentions, links), URL, method (e.g., web app, phone, Facebook), geographical coordinates</li>\n",
    "    <li><b>author level.</b> ID, screen name, location, follower count, friend count, picture URL</li>\n",
    "    <li><b>retweet level.</b> ID of original tweet, ID and screen name of original author</li></ul>\n",
    "Many of these variables contained missing data or required recoding of values. In particular, the author location and the time-date variable required considerable wrangling. To reclassify the large number of nonstandardized location values, created dictionaries associating U.S. state names and abbreviations to the value \"USA\" and mapped original values to new values using a for loop. This left a large number of U.S. locations that needed to be manually reassigned to the \"USA\" category using regular expression. The time-date needed to be transformed into a timestamp data type and stripped of the time information so that it could be used for time series analysis.</p> \n",
    "<p>In addition to preparing existing variables for analysis, we created several new variables measuring latent features. We calculated sentiment scores using the AFINN and VADER lexicons because both performed well in previous studies (Islam and Zibram, n.d.). Topics were modelled using Gensim and Latent Dirichlet Allocation (LDA), with five being the number of topics we eventually settled on. The word vectors for our topics are:<ol>\n",
    "    <li>group, get, watch, american, new, refugee, crisis, people, right, guess</li>\n",
    "    <li>caravan, know, trump, family, u, prevent, implement, vote, need, today</li>\n",
    "    <li>europe, pact, hungary, voice, brussels, v_of_europe, illegal, life, police, street</li>\n",
    "    <li>child, gang, free, part, say, government, u.s., youth, worker, salvadoran</li>\n",
    "    <li>border, law, cross, arizona, via, bus, section, unsecured, unloads, stop</li></ol>\n",
    "The language of the tweets, as opposed to the language of the authors as indicated in their profiles, was determined using the langdetect module, revealing 9,680 instances when the language of the tweet does not match the language of the author. We also created an indicator variable for whether the tweet was a retweet or not.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary Statistics & Visualizations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>References</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Islam, M. R. (n.d.) A Comparison of Dictionary Building Methods for Sentiment Analysis in Software Engineering Text. Retrieved from http://cs.uno.edu/~zibran/resources/MyPapers/DictionaryEvaluation.pdf</p>\n",
    "\n",
    "<p>Ozturk, N., & Ayvaz, S. (2018). Sentiment analysis on Twitter: A text mining approach to the Syrian refugee crisis. <i>Telematics and Informatics</i>, 35, 136-147.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
